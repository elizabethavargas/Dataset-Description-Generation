{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtfBnEPisEBqNvdiXY1aPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizabethavargas/Dataset-Description-Generation/blob/main/create_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset"
      ],
      "metadata": {
        "id": "HiAO59G9cDjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# packages\n",
        "import random\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import pickle\n",
        "import json"
      ],
      "metadata": {
        "id": "Zf3riUQTd3Sf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get list of datasets on NYC Open Data"
      ],
      "metadata": {
        "id": "7uh3q5qBbG87"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02c0186e"
      },
      "source": [
        "def list_nyc_open_data_datasets():\n",
        "  \"\"\"\n",
        "    Fetches all datasets from the NYC Open Data Socrata API.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: List of {\"id\": <id>, \"name\": <name>} dictionaries.\n",
        "                    Returns [] if any error occurs.\n",
        "    \"\"\"\n",
        "\n",
        "  # Base URL for the NYC Open Data API\n",
        "  base_url = \"https://data.cityofnewyork.us/api/views.json\"\n",
        "\n",
        "  try:\n",
        "      response = requests.get(base_url)\n",
        "      response.raise_for_status()  # Raise an exception for bad status codes\n",
        "      datasets_data = response.json()\n",
        "\n",
        "      # Extract id and name for each dataset\n",
        "      datasets_list = []\n",
        "      for dataset in datasets_data:\n",
        "          if 'id' in dataset and 'name' in dataset:\n",
        "              datasets_list.append({'id': dataset['id'], 'name': dataset['name']})\n",
        "\n",
        "      # Print confirmation message\n",
        "      print(f\"Successfully listed {len(datasets_list)} datasets.\")\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error fetching data: {e}\")\n",
        "  except ValueError:\n",
        "      print(\"Error decoding JSON response. The response might not be in JSON format.\")\n",
        "\n",
        "  return datasets_list"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_closest_match(candidates, references):\n",
        "    \"\"\"\n",
        "    Returns the candidate string that is most similar to any of the reference strings.\n",
        "\n",
        "    Args:\n",
        "        candidates (list[str]): List of strings to choose from.\n",
        "        references (list[str]): List of reference strings to compare against.\n",
        "\n",
        "    Returns:\n",
        "        str | None: The candidate with highest similarity to any reference,\n",
        "                    or None if candidates is empty.\n",
        "    \"\"\"\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    best_match = None\n",
        "    highest_similarity = -1\n",
        "\n",
        "    for candidate in candidates:\n",
        "        for reference in references:\n",
        "            similarity = SequenceMatcher(\n",
        "                None,\n",
        "                candidate.lower(),\n",
        "                reference.lower()\n",
        "            ).ratio()\n",
        "\n",
        "            if similarity > highest_similarity:\n",
        "                highest_similarity = similarity\n",
        "                best_match = candidate\n",
        "\n",
        "    return best_match\n"
      ],
      "metadata": {
        "id": "h0RJHjFxcnZK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example_rows(df, max_chars=150):\n",
        "    \"\"\"\n",
        "    Formats the first n rows of a DataFrame as clean JSON-like examples for LLM prompts.\n",
        "    - Truncates long strings/numbers.\n",
        "    - Removes NaN values.\n",
        "    \"\"\"\n",
        "    example = {}\n",
        "    for col, val in df.iloc[0].items():\n",
        "        # Simplify nested dicts or long text\n",
        "        if isinstance(val, (dict, list)):\n",
        "            val_str = json.dumps(val)\n",
        "        else:\n",
        "            val_str = str(val)\n",
        "        if len(val_str) > max_chars:\n",
        "            val_str = val_str[:max_chars] + \"...\"\n",
        "        if val_str not in (\"nan\", \"None\", \"\"):\n",
        "            example[col] = val_str\n",
        "    return example"
      ],
      "metadata": {
        "id": "u8Jx8RvqSKm1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_dataset_info(dataset_id, app_token = \"L76aBvmvvFwme9Q46GQJ3qtf8\"):\n",
        "    \"\"\"\n",
        "    Fetches data example, metadata, tags, column descriptions, and data dictionary\n",
        "    for a single NYC Open Data dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_id (dict): A string of the dataset id found in the URL of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        dict or None: A dataset_info object, or None if something failed.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Querying dataset (ID: {dataset_id}) ---\")\n",
        "\n",
        "\n",
        "    # URLs\n",
        "    dataset_url = f\"https://data.cityofnewyork.us/resource/{dataset_id}.json\"\n",
        "    metadata_url = f\"https://data.cityofnewyork.us/api/views/{dataset_id}.json\"\n",
        "\n",
        "    # FETCH SAMPLE DATA\n",
        "    try:\n",
        "        data_response = requests.get(\n",
        "            dataset_url,\n",
        "            headers={\"X-App-Token\": app_token},\n",
        "            params={'$limit': 2}\n",
        "        )\n",
        "        data_response.raise_for_status()\n",
        "        data = data_response.json()\n",
        "\n",
        "        if not data:\n",
        "            print(f\"No data returned for dataset: {dataset_id}\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        if df.empty:\n",
        "            print(f\"No rows returned for dataset: {dataset_id}\")\n",
        "            return None\n",
        "\n",
        "        data_example = format_example_rows(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving sample data for {dataset_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # FETCH METADATA\n",
        "    try:\n",
        "        metadata_response = requests.get(metadata_url)\n",
        "        metadata_response.raise_for_status()\n",
        "        metadata = metadata_response.json()\n",
        "\n",
        "        if not metadata:\n",
        "            print(\"No metadata returned.\")\n",
        "            return None\n",
        "\n",
        "        # Basic metadata\n",
        "        dataset_name = metadata.get(\"name\", \"N/A\")\n",
        "        category = metadata.get(\"category\", \"N/A\")\n",
        "        description_raw = metadata.get(\"description\", \"\")\n",
        "        description = \"\\n\".join([line for line in description_raw.splitlines() if line.strip()])\n",
        "        agency = metadata.get(\"metadata\", {}).get(\"custom_fields\", {})\\\n",
        "                        .get(\"Dataset Information\", {}).get(\"Agency\", \"N/A\")\n",
        "        tags = metadata.get(\"tags\", [])\n",
        "        column_info = {}\n",
        "\n",
        "        # COLUMN DESCRIPTIONS FROM METADATA\n",
        "        for col in metadata.get(\"columns\", []):\n",
        "            name = col.get(\"name\", \"\")\n",
        "            desc = col.get(\"description\", \"\")\n",
        "            if desc:\n",
        "                column_info[name] = desc\n",
        "\n",
        "\n",
        "        # TRY DATA DICTIONARY FILE IF METADATA HAS NO COLUMN INFO\n",
        "        attachments = metadata.get(\"metadata\", {}).get(\"attachments\", [])\n",
        "        if attachments and not column_info:\n",
        "            print(\"COLUMN INFO FROM DATA DICTIONARY FILE\")\n",
        "\n",
        "            # Find closest file match\n",
        "            filenames = [a[\"filename\"] for a in attachments]\n",
        "            match = find_closest_match(\n",
        "                filenames,\n",
        "                [\"data dictionary\", \"column descriptions\", \"column definitions\"]\n",
        "            )\n",
        "\n",
        "            if match:\n",
        "                attach = next(a for a in attachments if a[\"filename\"] == match)\n",
        "                file_id = attach.get(\"assetId\")\n",
        "                file_url = (\n",
        "                    f\"https://data.cityofnewyork.us/api/views/{dataset_id}/files/\"\n",
        "                    f\"{file_id}?download=true&filename={match}\"\n",
        "                )\n",
        "                print(f\"Downloading attached dictionary: {match}\")\n",
        "\n",
        "                try:\n",
        "                    file_response = requests.get(file_url)\n",
        "                    file_response.raise_for_status()\n",
        "\n",
        "                    excel_file = BytesIO(file_response.content)\n",
        "                    xls = pd.ExcelFile(excel_file)\n",
        "\n",
        "                    # pick best sheet\n",
        "                    sheet = find_closest_match(\n",
        "                        xls.sheet_names,\n",
        "                        [\"data dictionary\", \"column descriptions\", \"column definitions\"]\n",
        "                    )\n",
        "\n",
        "                    df_preview = pd.read_excel(xls, sheet_name=sheet, header=None)\n",
        "\n",
        "                    # Detect header row\n",
        "                    def detect_header_row(df_full):\n",
        "                        for i in range(min(10, len(df_full))):\n",
        "                            row = df_full.iloc[i].astype(str).str.lower()\n",
        "                            keywords = [\"column\", \"name\", \"description\", \"field\"]\n",
        "                            matches = sum(any(k in cell for k in keywords) for cell in row)\n",
        "                            if matches >= 2:\n",
        "                                return i\n",
        "                        return 0\n",
        "\n",
        "                    header = detect_header_row(df_preview)\n",
        "                    df_dict = pd.read_excel(xls, sheet_name=sheet, header=header)\n",
        "\n",
        "                    # Match columns\n",
        "                    name_col = find_closest_match(\n",
        "                        df_dict.columns,\n",
        "                        [\"column\", \"column name\", \"field\", \"field name\"]\n",
        "                    )\n",
        "                    desc_col = find_closest_match(\n",
        "                        df_dict.columns,\n",
        "                        [\"description\", \"definition\", \"column description\"]\n",
        "                    )\n",
        "\n",
        "                    if name_col and desc_col:\n",
        "                        for _, row in df_dict.iterrows():\n",
        "                            name_val = str(row[name_col]).strip()\n",
        "                            desc_val = str(row[desc_col]).strip()\n",
        "                            if desc_val:\n",
        "                                column_info[name_val] = desc_val\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing dictionary file: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching metadata for {dataset_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # RETURN FINAL OBJECT\n",
        "    dataset_info = {\n",
        "        \"dataset_id\": dataset_id,\n",
        "        \"dataset_name\": dataset_name,\n",
        "        \"data_example\": data_example,\n",
        "        \"category\": category,\n",
        "        \"description\": description,\n",
        "        \"agency\": agency,\n",
        "        \"tags\": tags,\n",
        "        \"column_info\": column_info,\n",
        "    }\n",
        "\n",
        "    print(f\"Finished dataset: {dataset_name}\")\n",
        "\n",
        "    return dataset_info\n"
      ],
      "metadata": {
        "id": "tDTY78cWdhD5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_all_datasets(output_path=\"datasets.pkl\", app_token=\"L76aBvmvvFwme9Q46GQJ3qtf8\"):\n",
        "    \"\"\"\n",
        "    Fetches all NYC Open Data datasets and saves detailed info to a pickle file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    output_path : str\n",
        "        Where to save the pickle file (default: 'datasets.pkl')\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of dataset info dicts (also saved to disk)\n",
        "    \"\"\"\n",
        "    datasets_list = list_nyc_open_data_datasets()\n",
        "    datasets = []\n",
        "\n",
        "    for dataset in datasets_list:\n",
        "        try:\n",
        "            info = fetch_dataset_info(dataset['id'])\n",
        "            if info:\n",
        "                datasets.append(info)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Skipping dataset {dataset.get('id', '?')}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Save result\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        pickle.dump(datasets, f)\n",
        "\n",
        "    return datasets\n"
      ],
      "metadata": {
        "id": "89EB-0UHdg7t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = fetch_all_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mAR9zBW1J6qL",
        "outputId": "5d26739c-3561-49b5-9ab0-65f2149df446"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: 2019-20 School Quality Guide HS DD.xlsx\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: 2019-20 School Quality Guide HS Transfer DD.xlsx\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: 2019-20 School Quality Guide High Schools\n",
            "\n",
            "--- Querying dataset (ID: kkng-ugna) ---\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: 2019-20 School Quality Guide High School Transfer\n",
            "\n",
            "--- Querying dataset (ID: 6umk-irkx) ---\n",
            "Error retrieving sample data for 6umk-irkx: 403 Client Error: Forbidden for url: https://data.cityofnewyork.us/resource/6umk-irkx.json?%24limit=2\n",
            "\n",
            "--- Querying dataset (ID: cvqn-xqrr) ---\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: 2019-20 School Quality Guide Early Childhood DD.xlsx\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: FY2020 Local Law 16 Final Report DD.xlsx\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: 2019-20 School Quality Guide Early Childhood\n",
            "\n",
            "--- Querying dataset (ID: 8vqd-3345) ---\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: FY2020 Local Law 16 Final Report\n",
            "\n",
            "--- Querying dataset (ID: mvn6-575n) ---\n",
            "No data returned for dataset: mvn6-575n\n",
            "\n",
            "--- Querying dataset (ID: hsst-tgws) ---\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: 2018-2019 Career_Technical_Education_Report DD.xlsx\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: 2018-2019 Career and Technical Education Report Law 174\n",
            "\n",
            "--- Querying dataset (ID: k5d2-tkrr) ---\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: City Council January 2021 Attendance.xlsx\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: Learning Preference City Remote Learning as of Jan 4, 2021 DD.xlsx\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: Learning Preference City Remote Learning - as of Jan 4, 2021\n",
            "\n",
            "--- Querying dataset (ID: xi2y-szfs) ---\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: 2020 Summer School Remote Learning DD.xlsx\n",
            "Error processing dictionary file: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Finished dataset: 2020 Summer School Remote Learning\n",
            "\n",
            "--- Querying dataset (ID: rrd7-vuvp) ---\n",
            "COLUMN INFO FROM DATA DICTIONARY FILE\n",
            "Downloading attached dictionary: 2020-21 Bilingual List Final Publication.xlsx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3709643502.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_all_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3687685852.py\u001b[0m in \u001b[0;36mfetch_all_datasets\u001b[0;34m(output_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malso\u001b[0m \u001b[0msaved\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdisk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdatasets_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_nyc_open_data_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-162423277.py\u001b[0m in \u001b[0;36mlist_nyc_open_data_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raise an exception for bad status codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mdatasets_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}