{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMvlxbMZnKvPhlicCLM+4V1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizabethavargas/Dataset-Description-Generation/blob/main/evaluation_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Evaluator Class"
      ],
      "metadata": {
        "id": "zlMDiT5_amD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d\"\n",
        "import unsloth\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X97OeqMDE71",
        "outputId": "fbfb1aba-689b-435d-8238-95c3e0a0ee02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d)\n",
            "  Using cached unsloth-2025.10.10-py3-none-any.whl\n",
            "Requirement already satisfied: unsloth_zoo>=2025.10.11 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2025.11.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (25.0)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.9.35)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.56.2)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.3.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.1.9)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.48.2)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.7.0)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.14.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.5.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.12.0)\n",
            "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.24.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.18.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.11->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.20.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.11.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git@31b667b54139962832ea2de890383eed14a0a17d) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_system_message = \"You are a helpful and precise assistant for checking the quality of the dataset description.\"\n",
        "evaluation_prompt = \"\"\"You will be given one tabular dataset description. Your task is to rate the description on 3 metrics.\n",
        "    Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
        "\n",
        "    Evaluation Criteria:\n",
        "    1. Completeness (1-10) - Evaluates how thoroughly the dataset description covers essential aspects such as the scope of data, query workloads, summary statistics, and possible tasks or applications.\n",
        "    A high score indicates that the description provides a comprehensive overview, including details on dataset size, structure, fields, and potential use cases.\n",
        "    2. Conciseness (1-10) - Measures the efficiency of the dataset description in conveying necessary information without redundancy.\n",
        "    A high score indicates that the description is succinct, avoiding unnecessary details while employing semantic types (e.g., categories, entities) to streamline communication.\n",
        "    3. Readability (1-10) -  Evaluates the logical flow and readability of the dataset description.\n",
        "    A high score suggests that the description progresses logically from one section to the next, creating a coherent and integrated narrative that facilitates understanding of the dataset.\n",
        "\n",
        "    Evaluation Steps:\n",
        "    Read the dataset description carefully and identify the main topic and key points. Assign a score for each criterion on a scale of 1 to 10, where 1 is the lowest and 10 is the highest based on the Evaluation Criteria.\n",
        "\n",
        "    Example 1:\n",
        "    Description: The dataset provides information on alcohol-impaired driving deaths and occupant deaths across various states in the United States. It includes data for 51 states, detailing the number of alcohol-impaired driving deaths and occupant deaths, with values ranging from 0 to 3723 and 0 to 10406, respectively. Each entry also contains the state abbreviation and its geographical coordinates. The dataset is structured with categorical and numerical data types, focusing on traffic safety and casualty statistics. Key attributes include state names, death counts, and location coordinates, making it a valuable resource for analyzing traffic safety trends and issues related to impaired driving.\n",
        "    Evaluation Form (scores ONLY): Completeness: 7, Conciseness: 9, Readability: 9\n",
        "\n",
        "    Example 2:\n",
        "    Description: The dataset provides a comprehensive overview of traffic safety statistics across various states in the United States, specifically focusing on alcohol-impaired driving deaths and occupant deaths. It includes data from 51 unique states, represented by their two-letter postal abbreviations, such as MA (Massachusetts), SD (South Dakota), AK (Alaska), MS (Mississippi), and ME (Maine). Each entry in the dataset captures critical information regarding the number of alcohol-impaired driving deaths and the total occupant deaths resulting from traffic incidents.\n",
        "    The column \"Alcohol-Impaired Driving Deaths\" is represented as an integer, indicating the number of fatalities attributed to alcohol impairment while driving. The dataset reveals a range of values, with the highest recorded number being 2367 deaths in Mississippi, highlighting the severity of the issue in certain regions. In contrast, states like Alaska report significantly lower figures, with only 205 alcohol-impaired driving deaths.\n",
        "    The \"Occupant Deaths\" column also consists of integer values, representing the total number of deaths among vehicle occupants, regardless of the cause. This data spans from 0 to 10406, with Mississippi again showing the highest number of occupant deaths at 6100, which raises concerns about overall traffic safety in the state.\n",
        "    Additionally, the dataset includes a \"Location\" column that provides geographical coordinates for each state, enhancing the spatial understanding of the data. The coordinates are formatted as latitude and longitude pairs, allowing for potential mapping and geographical analysis of traffic safety trends.\n",
        "    Overall, this dataset serves as a valuable resource for researchers, policymakers, and public safety advocates aiming to understand and address the impact of alcohol on driving safety across different states. It highlights the need for targeted interventions and policies to reduce alcohol-impaired driving incidents and improve occupant safety on the roads.\n",
        "    Evaluation Form (scores ONLY): Completeness: 8, Conciseness: 7, Readability: 8\n",
        "\n",
        "    Please provide scores for the given dataset description based on the Evaluation Criteria. Do not include any additional information or comments in your response.\"\"\"\n",
        "\n",
        "\n",
        "evaluation_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-70B-Instruct\",\n",
        "    \"unsloth/Qwen2-72B-Instruct\",\n",
        "]\n",
        "\n",
        "class HFEvaluator:\n",
        "    \"\"\"Evaluates descriptions using a Hugging Face model\"\"\"\n",
        "\n",
        "    def __init__(self, model_name):\n",
        "        if model_name not in evaluation_models:\n",
        "            raise ValueError(f\"Model '{model_name}' is not in the list of available models. \"\n",
        "                             f\"Choose from: {evaluation_models}\")\n",
        "        self.model_name = model_name\n",
        "        self.template = evaluation_prompt\n",
        "        self.system_message = evaluation_system_message\n",
        "\n",
        "        # Load model + tokenizer\n",
        "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name=model_name,\n",
        "            max_seq_length=4096,\n",
        "            dtype=None,\n",
        "            load_in_4bit=True,\n",
        "        )\n",
        "\n",
        "        FastLanguageModel.for_inference(self.model)\n",
        "\n",
        "        if \"Qwen\" in model_name:\n",
        "            self.tokenizer.eos_token = \"<|im_end|>\"       # real EOS\n",
        "            self.tokenizer.pad_token = \"<|endoftext|>\"    # real PAD\n",
        "            self.tokenizer.bos_token = self.tokenizer.pad_token\n",
        "\n",
        "            self.eos_ids = [self.tokenizer.eos_token_id]\n",
        "            self.pad_id = self.tokenizer.pad_token_id\n",
        "            self.bos_id = self.tokenizer.bos_token_id\n",
        "\n",
        "        else:  # LLaMA\n",
        "            self.eos_ids = [\n",
        "                self.tokenizer.eos_token_id,\n",
        "                self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "            ]\n",
        "\n",
        "    def evaluate_description(self, description):\n",
        "        \"\"\"Evaluates a description given a prompt and temperature\"\"\"\n",
        "\n",
        "        # Build final message content in one step\n",
        "        user_content = (\n",
        "            f\"{self.template}\\n\"\n",
        "            f\"Description: {description}\\n\"\n",
        "            \"Evaluation Form (scores ONLY): \"\n",
        "        )\n",
        "\n",
        "        prompt = self.tokenizer.apply_chat_template(\n",
        "            [\n",
        "                {\"role\": \"system\", \"content\": self.system_message},\n",
        "                {\"role\": \"user\", \"content\": user_content},\n",
        "            ],\n",
        "            tokenize=False,\n",
        "        )\n",
        "\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        if \"Llama\" in self.model_name or \"Meta-Llama\" in self.model_name:\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=50,\n",
        "                    do_sample=True,\n",
        "                    temperature=0.3,\n",
        "                    num_beams=1,\n",
        "                    eos_token_id=self.eos_ids,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    use_cache=True,\n",
        "                )\n",
        "\n",
        "        else:  # Qwen branch\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=50,\n",
        "                    do_sample=True,\n",
        "                    temperature=0.3,\n",
        "                    eos_token_id=self.eos_ids,\n",
        "                    pad_token_id=self.pad_id,\n",
        "                    bos_token_id=self.bos_id,\n",
        "                    use_cache=True,\n",
        "                )\n",
        "\n",
        "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        return text[len(prompt):].strip()\n"
      ],
      "metadata": {
        "id": "RXaeQFS6S1tR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hf auth login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvfem6LiHmgO",
        "outputId": "d8648902-6e53-4f3e-dcc4-1d6ea3987ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "The token `ergth` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `ergth`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "description = \"The description should be clear and concise, explaining the purpose and potential uses of the dataset.\\nAnswer: Without any specific details about the dataset, it's challenging to provide a comprehensive description. However, given that the title, agency, category, tags, and column definitions are all unspecified, we can infer that this dataset might serve as a placeholder or a starting point for various data-related tasks. It could potentially be utilized for general data analysis, data visualization projects, or as a foundation for developing more specialized datasets tailored to specific industries or research areas. Its flexibility allows it to be adapted to numerous applications depending on the user's needs and objectives. Since there are no predefined columns or tags, users have the freedom to structure the data according to their requirements, making it suitable for a wide range of data-driven projects. Overall, this dataset represents a versatile resource that can be customized and leveraged for diverse purposes within the realm of data science and analytics.\"\n",
        "\n",
        "llama_evaluator = HFEvaluator(\"unsloth/Meta-Llama-3.1-70B-Instruct\")\n",
        "llama_evaluator.evaluate_description(description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "AkI2r0mCS1mA",
        "outputId": "20f32361-9886-4ab6-feb1-1d72cbb608dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.10.10: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4140997854.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The description should be clear and concise, explaining the purpose and potential uses of the dataset.\\nAnswer: Without any specific details about the dataset, it's challenging to provide a comprehensive description. However, given that the title, agency, category, tags, and column definitions are all unspecified, we can infer that this dataset might serve as a placeholder or a starting point for various data-related tasks. It could potentially be utilized for general data analysis, data visualization projects, or as a foundation for developing more specialized datasets tailored to specific industries or research areas. Its flexibility allows it to be adapted to numerous applications depending on the user's needs and objectives. Since there are no predefined columns or tags, users have the freedom to structure the data according to their requirements, making it suitable for a wide range of data-driven projects. Overall, this dataset represents a versatile resource that can be customized and leveraged for diverse purposes within the realm of data science and analytics.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mllama_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHFEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unsloth/Meta-Llama-3.1-70B-Instruct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mllama_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2291252442.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Load model + tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mfast_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mmodel_name\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mmax_seq_length\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[0m\n\u001b[1;32m   2032\u001b[0m             )\n\u001b[1;32m   2033\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m             model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   2035\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m                 \u001b[0mdevice_map\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5158\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5160\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5162\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    118\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Retrieval Evaluation\n",
        "Purpose: Measures how generated descriptions improve dataset search and findability.\n",
        "\n",
        "- Method: Integrates descriptions into a keyword-based search engine.\n",
        "- Metric: Normalized Discounted Cumulative Gain (NDCG@k).\n",
        "- Evaluates ranking quality by comparing ideal vs. actual search results.\n",
        "- Higher scores mean relevant datasets appear earlier in search results.\n",
        "- Tools: Tested with BM25 (lexical keyword matching) and SPLADE (semantic term expansion)."
      ],
      "metadata": {
        "id": "5tRImKK23_6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# Example: relevance scores for 5 datasets\n",
        "true_relevance = [[3, 2, 3, 0, 1]]   # ground truth relevance\n",
        "scores = [[0.9, 0.8, 0.7, 0.2, 0.3]] # model scores\n",
        "\n",
        "# Compute NDCG@5\n",
        "ndcg = ndcg_score(true_relevance, scores, k=5)\n",
        "print(\"NDCG@5:\", ndcg)\n"
      ],
      "metadata": {
        "id": "cnEeIpVV3wFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference-Based Evaluation\n",
        "Purpose: Compares generated descriptions against existing dataset descriptions.\n",
        "\n",
        "Metrics:\n",
        "METEOR: Accounts for precision, recall, synonyms, and stemming.\n",
        "ROUGE: Measures overlap of n-grams, sequences, and recall.\n",
        "BERTScore: Uses contextual embeddings to assess semantic similarity.\n",
        "Outcome: Determines how closely AutoDDGs descriptions match human-written ones in wording and meaning."
      ],
      "metadata": {
        "id": "iyWF8FEQ4WbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "corpus = [\n",
        "    \"health insurance premiums liabilities assets\",\n",
        "    \"citi bike trips 2022\",\n",
        "    \"yellow taxi trip data multiple years\"\n",
        "]\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "query = \"insurance financial data\"\n",
        "scores = bm25.get_scores(query.split(\" \"))\n",
        "print(scores)\n"
      ],
      "metadata": {
        "id": "LeI7OWiL3wJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METEOR\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "\n",
        "reference = \"This dataset contains wind speed and direction measurements.\"\n",
        "candidate = \"Wind speed and direction data collected during 2003.\"\n",
        "print(\"METEOR:\", meteor_score([reference], candidate))\n",
        "\n",
        "# ROUGE\n",
        "from rouge_score import rouge_scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(reference, candidate)\n",
        "print(\"ROUGE:\", scores)\n",
        "\n",
        "# BERTScore\n",
        "from bert_score import score\n",
        "cands = [candidate]\n",
        "refs = [reference]\n",
        "P, R, F1 = score(cands, refs, lang=\"en\", verbose=True)\n",
        "print(\"BERTScore F1:\", F1.mean().item())\n"
      ],
      "metadata": {
        "id": "Rv_azrFj3wML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "from typing import Dict, Iterable, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from beartype import beartype\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "\n",
        "@beartype\n",
        "def compute_dcg(relevances: Iterable[float], p: int) -> float:\n",
        "    \"\"\"\n",
        "    Discounted cumulative gain at rank p\n",
        "\n",
        "    Args:\n",
        "        relevances: Relevance scores\n",
        "        p: Cut-off rank\n",
        "\n",
        "    Returns:\n",
        "        DCG value\n",
        "    \"\"\"\n",
        "\n",
        "    dcg = 0.0\n",
        "    for index, relevance in enumerate(relevances):\n",
        "        if index >= p:\n",
        "            break\n",
        "        dcg += (2**relevance - 1) / math.log2(index + 2)\n",
        "    return dcg\n",
        "\n",
        "\n",
        "@beartype\n",
        "def compute_avg_single_Q(\n",
        "    stats: Dict[str, Dict[str, Dict[str, List[float]]]],\n",
        "    description_version_key: str,\n",
        "    Q_key: str,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Average nested metrics into a DataFrame by index version\n",
        "\n",
        "    Args:\n",
        "        stats: Nested metrics dict\n",
        "        description_version_key: Key selecting description version\n",
        "        Q_key: Key selecting metric group\n",
        "\n",
        "    Returns:\n",
        "        DataFrame of averaged metrics\n",
        "    \"\"\"\n",
        "\n",
        "    averages: Dict[str, Dict[str, float]] = {}\n",
        "    ndcg_dicts = stats[description_version_key][Q_key]\n",
        "    for index_version, ndcg_metric in ndcg_dicts.items():\n",
        "        averages[index_version] = {\n",
        "            key: float(np.average(scores)) for key, scores in ndcg_metric.items()\n",
        "        }\n",
        "    return pd.DataFrame(averages)\n",
        "\n",
        "\n",
        "@beartype\n",
        "def compute_ndcg(\n",
        "    retrieved_relevances: Iterable[float], ideal_relevances: Iterable[float], p: int\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Normalised DCG at rank p\n",
        "\n",
        "    Args:\n",
        "        retrieved_relevances: Relevances by retrieved order\n",
        "        ideal_relevances: Relevances by ideal order\n",
        "        p: Cut-off rank\n",
        "\n",
        "    Returns:\n",
        "        nDCG value\n",
        "    \"\"\"\n",
        "\n",
        "    dcg = compute_dcg(retrieved_relevances, p)\n",
        "    idcg = compute_dcg(ideal_relevances, p)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "\n",
        "@beartype\n",
        "def downstream_task_rank(\n",
        "    documents: List[str],\n",
        "    query: str,\n",
        "    relevances: List[float],\n",
        "    ks: Iterable[int],\n",
        "    debug: bool = False,\n",
        ") -> Dict[int, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    BM25 ranking with nDCG@k over the inputted documents\n",
        "\n",
        "    Args:\n",
        "        documents: List of document texts\n",
        "        query: Query string\n",
        "        relevances: Ground-truth relevance scores\n",
        "        ks: List of cut-off values\n",
        "        debug: Print debug output if True\n",
        "\n",
        "    Returns:\n",
        "        Mapping k -> metrics\n",
        "    \"\"\"\n",
        "\n",
        "    def _compute_ndcg(relevance_true: List[float], relevance_test: List[float], k: int) -> float:\n",
        "        ideal_dcg = np.sum(np.array(relevance_true) / np.log2(np.arange(2, k + 2)))\n",
        "        dcg = np.sum(np.array(relevance_test) / np.log2(np.arange(2, k + 2)))\n",
        "        return float(dcg / ideal_dcg)\n",
        "\n",
        "    tokenized_corpus = [doc.lower().split() for doc in documents]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    tokenized_query = query.lower().split()\n",
        "    if debug:\n",
        "        print(tokenized_query)\n",
        "\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    sorted_rel_true = sorted(relevances, reverse=True)\n",
        "    sorted_rel_test = np.array(relevances)[sorted_indices].tolist()\n",
        "\n",
        "    results: Dict[int, Dict[str, float]] = {}\n",
        "    for k in ks:\n",
        "        ndcg = _compute_ndcg(sorted_rel_true[:k], sorted_rel_test[:k], k)\n",
        "        results[k] = {\"ndcg\": ndcg}\n",
        "    return results"
      ],
      "metadata": {
        "id": "mjDL6rzH6YHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}